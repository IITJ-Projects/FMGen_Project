# Conversational AI Agent - Production Docker Compose Configuration
# Docker Compose version 3.9 (version attribute removed - handled automatically)
# Services: ASR (faster-whisper) → RAG (Qdrant) → LLM (LLaMA-3-8B) → TTS (MeloTTS)
# Orchestrated by Vocode pipeline

services:
  # ASR Service - faster-whisper-medium with FastAPI wrapper
  asr-service:
    build:
      context: ./asr_service
      dockerfile: Dockerfile
    container_name: zevo-asr
    ports:
      - "8001:8001"
    volumes:
      - asr_model_cache:/app/models
      - ./logs:/app/logs
    networks:
      - zevo-network
    environment:
      - MODEL_NAME=medium.en
      - DEVICE=cpu #cuda
      - COMPUTE_TYPE=int8 #float16
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # LLM Service - LLaMA-3-8B Instruct with vLLM (GPU required)
  llm-service:
    build:
      context: ./llm_service
      dockerfile: Dockerfile
    container_name: zevo-llm
    ports:
      - "8002:8002"
    volumes:
      - llm_model_cache:/app/models
      - ./logs:/app/logs
      - ./llama3-model:/app/llama3-model
    networks:
      - zevo-network
    environment:
      - MODEL_NAME=/app/llama3-model/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/8afb486c1db24fe5011ec46dfbe5b5dccdb575c2
      - QUANTIZATION=none
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.9
      - DEVICE=cuda # use cuda for gpu acceleration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 5m
      timeout: 30s
      retries: 3
      start_period: 120s
    restart: unless-stopped

  # RAG Service - Qdrant Vector Database with embeddings
  rag-service:
    build:
      context: ./rag_service
      dockerfile: Dockerfile
    container_name: zevo-rag
    ports:
      - "8004:8004"
    volumes:
      - embedding_models:/app/embedding_models
      - reranker_models:/app/reranker_models
      - ./logs:/app/logs
    networks:
      - zevo-network
    environment:
      - QDRANT_HOST=qdrant-db
      - QDRANT_PORT=6333
      - BGE_MODEL_NAME=BAAI/bge-large-en-v1.5
      - MULTILINGUAL_MODEL_NAME=intfloat/multilingual-e5-large
      - RERANKER_MODEL_NAME=BAAI/bge-reranker-large
    depends_on:
      - qdrant-db
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # Qdrant Vector Database
  qdrant-db:
    image: qdrant/qdrant:latest
    container_name: zevo-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - zevo-network
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    # Health check removed - Qdrant minimal image doesn't have wget/curl
    # Health is verified by RAG service's /health endpoint which checks Qdrant connectivity
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  # TTS Service - MeloTTS with FastAPI streaming wrapper
  tts-service:
    build:
      context: ./tts_service
      dockerfile: Dockerfile
    container_name: zevo-tts
    ports:
      - "8003:8003"
    volumes:
      - tts_model_cache:/app/models
      - ./logs:/app/logs
    networks:
      - zevo-network
    environment:
      - MODEL_NAME=melo-tts
      - VOICE_ID=default
      - STREAMING=true
      - SAMPLE_RATE=24000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # RAG Ingestion Service - File upload and processing
  rag-ingestion-service:
    build:
      context: ./rag_ingestion_app
      dockerfile: Dockerfile
    container_name: zevo-rag-ingestion
    ports:
      - "8005:8005"
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    networks:
      - zevo-network
    environment:
      - RAG_SERVICE_URL=http://rag-service:8004
      - LLM_SERVICE_URL=http://llm-service:8002
    # Temporarily comment out depends_on to avoid recreation
    #depends_on:
    #  - rag-service
    #  - llm-service
    # Use restart: unless-stopped to avoid recreation conflicts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # Frontend App - SPA for testing pipeline
  frontend-app:
    build:
      context: ./frontend_app
      dockerfile: Dockerfile
    container_name: zevo-frontend
    ports:
      - "8080:8080"
    networks:
      - zevo-network
    environment:
      - ORCH_URL=http://orchestration-service:8000
    depends_on:
      - orchestration-service
    restart: unless-stopped

  # Orchestration Service - Vocode pipeline coordinator
  orchestration-service:
    build:
      context: ./orchestration_service
      dockerfile: Dockerfile
    container_name: zevo-orchestration
    ports:
      - "8000:8000"
    volumes:
      - vocode_cache:/app/cache
      - ./logs:/app/logs
      - ./config:/app/config
    networks:
      - zevo-network
    environment:
      - ASR_SERVICE_URL=http://asr-service:8001
      - LLM_SERVICE_URL=http://llm-service:8002
      - RAG_SERVICE_URL=http://rag-service:8004
      - TTS_SERVICE_URL=http://tts-service:8003
      - QDRANT_HOST=qdrant-db
      - QDRANT_PORT=6333
      - FRONTEND_ORIGIN=http://164.52.194.203:8080
      - LOG_LEVEL=INFO
    depends_on:
      - asr-service
      - llm-service
      - rag-service
      - tts-service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

# Custom network for inter-service communication
networks:
  zevo-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Persistent volumes for data and model storage
volumes:
  # Model caches for each service
  asr_model_cache:
    driver: local
  llm_model_cache:
    driver: local
  tts_model_cache:
    driver: local

  # Qdrant vector database storage
  qdrant_data:
    driver: local

  # Embedding and reranker models
  embedding_models:
    driver: local
  reranker_models:
    driver: local

  # Vocode orchestration cache
  vocode_cache:
    driver: local
